{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ced5316",
   "metadata": {},
   "source": [
    "## Pretraining on Unlabeled Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e182523d",
   "metadata": {},
   "source": [
    "#### 5.1 - Evaluating Generative Text Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d50c99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ee74794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you Aeiman Byeswickattributeometer inspector Normandy freezerigrate\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"'<|endoftext|>'\"})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) #.unsqueeze(0) adds batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb289f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],\n",
    "                       [  40, 1107, 588]])\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345],\n",
    "                        [1107, 588, 11311]])\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)  # disables gradient tracking since we aren't training yet\n",
    "probas = torch.softmax(logits, dim=-1)  # probability of each token in the vocabulary\n",
    "print(probas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aeaadd3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "594e8042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\"\n",
    "      f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3642ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10cb25e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5b8dff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-10.7940)\n",
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)\n",
    "\n",
    "neg_avg_log_probas = -1 * avg_log_probas\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80f28717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4b58374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a491e44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab1311b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a5def73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = .80\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fb6969e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463d069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check to let me play with a bigger context length and tweak train_ratio accordingly\n",
    "\n",
    "if total_tokens * (train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the training loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"increase the `training_ratio`\")\n",
    "\n",
    "if total_tokens * (1-train_ratio) < GPT_CONFIG_124M[\"context_length\"]:\n",
    "    print(\"Not enough tokens for the validation loader. \"\n",
    "          \"Try to lower the `GPT_CONFIG_124M['context_length']` or \"\n",
    "          \"decrease the `training_ratio`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f7d5c5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "torch.Size([2, 1024]) torch.Size([2, 1024])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([1, 1024]) torch.Size([1, 1024])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6e13c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training tokens: 4096\n",
      "Validation tokens: 1024\n",
      "All tokens: 5120\n"
     ]
    }
   ],
   "source": [
    "# Token size sanity check\n",
    "\n",
    "train_tokens = 0\n",
    "for input_batch, target_batch in train_loader:\n",
    "    train_tokens += input_batch.numel()\n",
    "\n",
    "val_tokens = 0\n",
    "for input_batch, target_batch in val_loader:\n",
    "    val_tokens += input_batch.numel()\n",
    "\n",
    "print(\"Training tokens:\", train_tokens)\n",
    "print(\"Validation tokens:\", val_tokens)\n",
    "print(\"All tokens:\", train_tokens + val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cfdc557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        # Reduce the number of batches to match the total number of batches in the data loader\n",
    "        # if num_batches exceeds the number of batches in the data loader\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d2a07e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.999300003051758\n",
      "Validation loss: 11.034719467163086\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# copying the following over in case I want to run on one of the MacBooks...probably want to tweak the context length too in that case\n",
    "\n",
    "# Note:\n",
    "# Uncommenting the following lines will allow the code to run on Apple Silicon chips, if applicable,\n",
    "# which is approximately 2x faster than on an Apple CPU (as measured on an M3 MacBook Air).\n",
    "# However, the resulting loss values may be slightly different.\n",
    "\n",
    "#if torch.cuda.is_available():\n",
    "#    device = torch.device(\"cuda\")\n",
    "#elif torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#else:\n",
    "#    device = torch.device(\"cpu\")\n",
    "#\n",
    "# print(f\"Using {device} device.\")\n",
    "\n",
    "\n",
    "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
    "\n",
    "\n",
    "torch.manual_seed(123) # For reproducibility due to the shuffling in the data loader\n",
    "\n",
    "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19835d6",
   "metadata": {},
   "source": [
    "#### 5.2 - Training an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d8d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I love typing as much as the next guy, but copying all this saves my wrists\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):         # dropout gets disabled below during evaluation for stable/reproducible results. Gradient tracking also disabled for efficiency\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e3ec143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.597, Val loss 10.016\n",
      "Every effort moves you, the, the,,, the, the,,, the, the.                                 \n",
      "Every effort moves you, the                                                \n",
      "Ep 3 (Step 000005): Train loss 7.311, Val loss 8.113\n",
      "Every effort moves you, the, the, the, the, the, the, the, the.                                 \n",
      "Every effort moves you, and, the                                              \n",
      "Every effort moves you the the, the the. Gisburn, and the of the the the. \"--, and the the the, and, and the, and the, and the. \". Gisburn, and, and the, and\n",
      "Ep 6 (Step 000010): Train loss 5.078, Val loss 7.047\n",
      "Every effort moves you know \"--I. Gisburn--the, and in the of the  \"--I. Gisburn--, and I had been of the, and, and I had been. Gisburn, and I had been\n",
      "Every effort moves you a was, and in the, and in the. Gisburn's the.                                 \n",
      "Ep 8 (Step 000015): Train loss 3.944, Val loss 6.866\n",
      "Every effort moves you know, and in the \", and in the--I of the of the \" of his pictures, and in the to have been, and he was, I had been the house of his pictures, and in a was, and I had been\n",
      "Every effort moves you know, and in the.    I--the. I.  I. Gisburn's.  I.    I. Gisburn's. I.     I\n",
      "Every effort moves you know,\" was his pictures--the he was not to me to the of the and in the--and the to me to have been, in the of his pictures, and he had been his pictures--and by a little was not to me,\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f99a119",
   "metadata": {},
   "source": [
    "note the above is way shittier than the book result, likely due to some measure of optimization around context length and train ratio...anyway\n",
    "\n",
    "predictably, more epochs helps a lot with train loss, but val loss still sucks for reasons that will likely be immediately explained\n",
    "...hilariously, val loss actually got worse with more epochs (like more than 15-20), so I guess overfitting is already happening (copilot wrote that last part lol, which makes my above sentence look dumb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a0c6cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.597, Val loss 10.016\n",
      "Every effort moves you, the, the,,, the, the,,, the, the.                                 \n",
      "Every effort moves you, the                                                \n",
      "Ep 3 (Step 000005): Train loss 7.311, Val loss 8.113\n",
      "Every effort moves you, the, the, the, the, the, the, the, the.                                 \n",
      "Every effort moves you, and, the                                              \n",
      "Every effort moves you the the, the the. Gisburn, and the of the the the. \"--, and the the the, and, and the, and the, and the. \". Gisburn, and, and the, and\n",
      "Ep 6 (Step 000010): Train loss 5.078, Val loss 7.047\n",
      "Every effort moves you know \"--I. Gisburn--the, and in the of the  \"--I. Gisburn--, and I had been of the, and, and I had been. Gisburn, and I had been\n",
      "Every effort moves you a was, and in the, and in the. Gisburn's the.                                 \n",
      "Ep 8 (Step 000015): Train loss 3.944, Val loss 6.866\n",
      "Every effort moves you know, and in the \", and in the--I of the of the \" of his pictures, and in the to have been, and he was, I had been the house of his pictures, and in a was, and I had been\n",
      "Every effort moves you know, and in the.    I--the. I.  I. Gisburn's.  I.    I. Gisburn's. I.     I\n",
      "Every effort moves you know,\" was his pictures--the he was not to me to the of the and in the--and the to me to have been, in the of his pictures, and he had been his pictures--and by a little was not to me,\n",
      "Ep 11 (Step 000020): Train loss 2.911, Val loss 6.766\n",
      "Every effort moves you know,\" she was not to have been his pictures--and I felt to me--and of the. \"Oh, in a little--and it.  \"Oh, as his pictures--and by a little to have been the his\n",
      "Every effort moves you know,\" was one of the, as it were, so inevitably the of the and in of the, and to me to have been, in the, and he said, he had been of the, of Jack's \"strong to have, and\n",
      "Ep 13 (Step 000025): Train loss 1.942, Val loss 6.690\n",
      "Every effort moves you know,\" was one--his, as it were, a good-rooms--as it was--and the to me to have been, in the, and he was, he had was to have him. It was not, and established, and\n",
      "Every effort moves you know,\" was one of the axioms he was a good-rooms--as it was no great surprise to me to have been his, the, and his glory, he had dropped his painting, he was a little, and established himself in\n",
      "Every effort moves you know,\" was one of the axioms he was a good-rooms--as he was no great surprise to me to have been, in the, and his glory, he had dropped his painting, he was a; and Mrs. Gis\n",
      "Ep 16 (Step 000030): Train loss 1.164, Val loss 6.791\n",
      "Every effort moves you know,\" was one of the axioms he was a good fellow enough--so it was no great surprise to me to hear that, in the, on a later day, I had to have him done by a; and Mrs. Gis\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisburn's an unusual degree to the display of this false virtuosity. The picture was one of Jack's \"strongest,\" as his\n",
      "Ep 18 (Step 000035): Train loss 0.603, Val loss 6.915\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisburn's an unusual degree to the display of this false virtuosity. The picture was one of Jack's \"strongest,\" as his\n",
      "Every effort moves you thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a rich widow, and established himself in\n",
      "Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed luncheon-table, when, on a later day, I had again run over from Monte Carlo; and Mrs. Gis\n",
      "Training completed in 0.12 minutes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to calculate the execution time\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 20\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# Note:\n",
    "# Uncomment the following code to show the execution time\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fa093ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd93c10c",
   "metadata": {},
   "source": [
    "Note the book's example starts overfitting after just the second epoch, but with our beeg context window + more epochs, we hit that threshold seemingly at 6.  Is there something to that mathematically?  Who knows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f959a131",
   "metadata": {},
   "source": [
    "#### 5.3 - Decoding Strategies to Control Randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "40dddd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(\"cpu\") # it kills me to do this\n",
    "model.eval() # I'll do this one I guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd9b999f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know,\" was one of the axioms he laid down across the Sevres and silver of an exquisitely appointed lun\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5e9e7a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# Suppose input is \"every effort moves you\", and the LLM\n",
    "# returns the following logits for the next token:\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# The next generated token is then as follows:\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a797b4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6796f3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 x closer\n",
      "0 x every\n",
      "0 x effort\n",
      "582 x forward\n",
      "2 x inches\n",
      "0 x moves\n",
      "0 x pizza\n",
      "343 x toward\n",
      "0 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample), minlength=len(probas))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e9e8c732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c557bec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bddb02a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float(\"-inf\")), \n",
    "    other=next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "66f3f199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bcc9c27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ddd9190b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you Mrs,\" was one of the axioms he had an object for by\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132a64b8",
   "metadata": {},
   "source": [
    "#### 5.4 - Loading and Saving Model Weights in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1d2d5ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ecb919f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "77127fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")\n",
    "\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09d3e4b",
   "metadata": {},
   "source": [
    "#### 5.5 - Loading Pretrained Weights from OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7bd916fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-14 16:14:58.370532: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-14 16:14:58.595123: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-14 16:15:01.082560: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 356kiB/s]\n",
      "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 4.10MiB/s]\n",
      "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 578kiB/s]\n",
      "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:19<00:00, 25.1MiB/s] \n",
      "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 33.4MiB/s]\n",
      "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 1.97MiB/s]\n",
      "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 2.79MiB/s]\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5387ea1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "07511683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cf590fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "44f7d7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f4cd0f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorry copying again\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "    \n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5ecdd650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you as far as the hand can go until the end of your turn unless something interrupts your control flow. As you may observe I did not use a trigger on this battle on the last turn. After 1 battle, your power is restored and is only affected\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=50,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa551ac8",
   "metadata": {},
   "source": [
    "OG output with my little tweaks (presumably) from earlier lol...\n",
    "\n",
    "Output text:\n",
    " Every effort moves you as far as the hand can go until the end of your turn unless something interrupts your control flow. As you may observe I did not use a trigger on this battle on the last turn. After 1 battle, your power is restored and is only affected"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
